{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from Dataset import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(tweet)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 3]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_tokens_per_period(all_matchs, n):\n",
    "    period_token_counts = {}\n",
    "    for match_name, df in all_matchs.items():\n",
    "        period_token_counts[match_name] = {}\n",
    "        grouped = df.groupby('ID')['Tweet']\n",
    "        for id_, tweets in grouped:\n",
    "            all_tokens = []\n",
    "            for tweet in tweets:\n",
    "                all_tokens.extend(tokenize_tweet(tweet))\n",
    "            counter = Counter(all_tokens)\n",
    "            top_n = counter.most_common(n)\n",
    "            period_token_counts[match_name][id_] = dict(top_n)\n",
    "    return period_token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token_matrix(period_token_counts):\n",
    "    all_tokens = set()\n",
    "    all_ids = set()\n",
    "    for match_dict in period_token_counts.values():\n",
    "        for id_, token_count_dict in match_dict.items():\n",
    "            all_tokens.update(token_count_dict.keys())\n",
    "            all_ids.add(id_)\n",
    "    \n",
    "    all_tokens = sorted(list(all_tokens))\n",
    "    all_ids = sorted(list(all_ids))\n",
    "    \n",
    "    matrix = pd.DataFrame(0, index=all_tokens, columns=all_ids)\n",
    "    \n",
    "    for match_dict in period_token_counts.values():\n",
    "        for id_, token_count_dict in match_dict.items():\n",
    "            for token, count in token_count_dict.items():\n",
    "                matrix.at[token, id_] = count\n",
    "    \n",
    "    matrix = matrix.fillna(0).astype(int)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_matrix(all_matchs_eval, train_vocab, n):\n",
    "    period_token_counts_eval = get_top_n_tokens_per_period(all_matchs_eval, n)\n",
    "    \n",
    "    all_ids_eval = set()\n",
    "    for match_dict in period_token_counts_eval.values():\n",
    "        for id_ in match_dict.keys():\n",
    "            all_ids_eval.add(id_)\n",
    "    all_ids_eval = sorted(list(all_ids_eval))\n",
    "    \n",
    "    evaluation_matrix = pd.DataFrame(0, index=train_vocab, columns=all_ids_eval)\n",
    "    \n",
    "    for match_dict in period_token_counts_eval.values():\n",
    "        for id_, token_count_dict in match_dict.items():\n",
    "            for token, count in token_count_dict.items():\n",
    "                if token in evaluation_matrix.index:\n",
    "                    evaluation_matrix.at[token, id_] = count\n",
    "    \n",
    "    evaluation_matrix = evaluation_matrix.fillna(0).astype(int)\n",
    "    return evaluation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(input_dim: int) -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=input_dim,\n",
    "                    kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # binaire\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp_classification(token_matrix_all, id_labels):\n",
    "    ids = token_matrix_all.columns.tolist()\n",
    "    y = np.array([id_labels[id_] for id_ in ids])\n",
    "    \n",
    "    X = token_matrix_all.T.values\n",
    "    \n",
    "    X_temp, X_test, y_temp, y_test, ids_temp, ids_test = train_test_split(\n",
    "        X, y, ids, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val, ids_train, ids_val = train_test_split(\n",
    "        X_temp, y_temp, ids_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    model = build_mlp_model(input_dim=X_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return model, (X_test, y_test, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_evaluation_set(model, evaluation_matrix):\n",
    "    ids_eval = evaluation_matrix.columns.tolist()\n",
    "    X_eval = evaluation_matrix.T.values\n",
    "    \n",
    "    y_pred_proba = model.predict(X_eval)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'ID': ids_eval,\n",
    "        'EventType': y_pred\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, all_matchs_cleaned, _, all_matchs_cleaned_eval = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "period_token_counts = get_top_n_tokens_per_period(all_matchs_cleaned, n)\n",
    "token_matrix_all = create_token_matrix(period_token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_labels = {}\n",
    "for df_match in all_matchs_cleaned.values():\n",
    "    for _, row in df_match.iterrows():\n",
    "        id_labels[row['ID']] = row['EventType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_data = run_mlp_classification(token_matrix_all, id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = token_matrix_all.index\n",
    "evaluation_matrix = create_evaluation_matrix(all_matchs_cleaned_eval, train_vocab, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = predict_on_evaluation_set(model, evaluation_matrix)\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
